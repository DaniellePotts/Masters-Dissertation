{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Lambda, Conv2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "import keras.backend as K\n",
    "\n",
    "from anyrl.rollouts import replay\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(action_len, img_rows=64, img_cols=64, img_channels=3, dueling=False, clip_value=1.0,\n",
    "                learning_rate=1e-4, nstep_reg=1.0, slmc_reg=1.0, l2_reg=10e-5):\n",
    "  input_img = Input(shape=(img_rows, img_cols, img_channels), name='input_img', dtype='float')\n",
    "  scale_img = Lambda(lambda x: x/255.)(input_img)\n",
    "  layer_1 = Conv2D(32, kernel_size=(8, 8), strides=(4, 4), padding='same',\n",
    "                     activation='relu', input_shape=(img_rows, img_cols, img_channels),\n",
    "                     kernel_initializer=initializers.glorot_normal(seed=31),\n",
    "                     kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                     bias_regularizer=regularizers.l2(l2_reg))(scale_img)#(input_img)\n",
    "  layer_2 = Conv2D(64, kernel_size=(4, 4), strides=(2, 2), padding='same', activation='relu',\n",
    "                    kernel_initializer=initializers.glorot_normal(seed=31),\n",
    "                    kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                    bias_regularizer=regularizers.l2(l2_reg))(layer_1)\n",
    "  layer_3 = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
    "                    kernel_initializer=initializers.glorot_normal(seed=31),\n",
    "                    kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                    bias_regularizer=regularizers.l2(l2_reg))(layer_2)\n",
    "  x = Flatten()(layer_3)\n",
    "  x = Dense(256, activation='relu',\n",
    "              kernel_initializer=initializers.glorot_normal(seed=31),\n",
    "              kernel_regularizer=regularizers.l2(l2_reg),\n",
    "              bias_regularizer=regularizers.l2(l2_reg))(x)\n",
    "  \n",
    "  if not dueling:\n",
    "    cnn_output = Dense(action_len,\n",
    "                           kernel_initializer=initializers.glorot_normal(seed=31),\n",
    "                           kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                           bias_regularizer=regularizers.l2(l2_reg), name='cnn_output')(x)\n",
    "  else:\n",
    "    print('duelling')\n",
    "  \n",
    "  cnn_model = Model(input_img, cnn_output)\n",
    "\n",
    "  input_img_dq = Input(shape=(img_rows, img_cols, img_channels), name='input_img_dq', dtype='float32')\n",
    "  input_img_nstep = Input(shape=(img_rows, img_cols, img_channels), name='input_img_nstep', dtype='float32')\n",
    "  dq_output = cnn_model(input_img_dq)\n",
    "  nstep_output = cnn_model(input_img_nstep)\n",
    "\n",
    "  input_is_expert = Input(shape=(1,), name='input_is_expert')\n",
    "  input_expert_action = Input(shape=(2,), name='input_expert_action', dtype='int32')\n",
    "  input_expert_margin = Input(shape=(action_len,), name='input_expert_margin')\n",
    "  \n",
    "  def slmc_operator(slmc_input):\n",
    "    is_exp = slmc_input[0]\n",
    "    sa_values = slmc_input[1]\n",
    "    exp_act = K.cast(slmc_input[2], dtype='int32')\n",
    "    exp_margin = slmc_input[3]\n",
    "\n",
    "    exp_val = tf.gather_nd(sa_values, exp_act)\n",
    "\n",
    "    max_margin = K.max(sa_values + exp_margin, axis=1)\n",
    "    max_margin_2 = max_margin - exp_val\n",
    "    max_margin_3 = K.reshape(max_margin_2,K.shape(is_exp))\n",
    "    max_margin_4 = tf.multiply(is_exp,max_margin_3)\n",
    "    return max_margin_4\n",
    "  \n",
    "  slmc_output = Lambda(slmc_operator, name='slmc_output')([input_is_expert, dq_output,\n",
    "                                                             input_expert_action, input_expert_margin])\n",
    "  \n",
    "  model = Model(inputs=[input_img_dq, input_img_nstep, input_is_expert, input_expert_action, input_expert_margin],\n",
    "                outputs=[dq_output, nstep_output, slmc_output])\n",
    "  \n",
    "  if clip_value is not None:\n",
    "    adam = Adam(lr=learning_rate, clipvalue=clip_value)\n",
    "  else:\n",
    "    adam = Adam(lr=learning_rate)\n",
    "  \n",
    "\n",
    "  model.compile(optimizer=adam,\n",
    "                loss=['mse','mse','mae'],\n",
    "                loss_weights=[1., nstep_reg, slmc_reg])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(env, train_model, target_model, exp_buffer, rep_buffer, action_len,max_timesteps=1000000,min_buffer_size=20000,\n",
    "                  epsilon_start = 0.99,epsilon_min=0.01,nsteps = 10, batch_size = 32,expert_margin=0.8,\n",
    "                  gamma=0.99,nstep_gamma=0.99):\n",
    "    \n",
    "    update_every = 10000\n",
    "    time_int = int(time.time())\n",
    "    nstep_state_deque = deque()\n",
    "    nstep_action_deque = deque()\n",
    "    nstep_rew_list = []\n",
    "    nstep_nexts_deque = deque()\n",
    "    nstep_done_deque = deque()\n",
    "    empty_by_one = np.zeros((1, 1))\n",
    "    empty_exp_action_by_one = np.zeros((1, 2))\n",
    "    empty_action_len_by_one = np.zeros((1, action_len))\n",
    "    \n",
    "    episode_start_ts = 0\n",
    "    \n",
    "    train_ts = -1\n",
    "    explore_ts = max_timesteps * 0.8\n",
    "    \n",
    "    loss = np.zeros((4,))\n",
    "    epsilon = epsilon_start\n",
    "    curr_obs = env.reset()\n",
    "    \n",
    "    exp_batch_size = int(batch_size / 4)\n",
    "    gen_batch_size = batch_size - exp_batch_size\n",
    "    \n",
    "    epsiode = 1\n",
    "    total_rew = 0.\n",
    "    \n",
    "    while train_ts < max_timesteps:\n",
    "        train_ts += 1\n",
    "        episode_start_ts += 1\n",
    "        \n",
    "        if random.random() <= epsilon:\n",
    "            action_command = env.action_space.sample()\n",
    "        else:\n",
    "            temp_curr_obs = np.array(curr_obs)\n",
    "            temp_curr_obs = temp_curr_obs.reshape(1, temp_curr_obs.shape[0], temp_curr_obs.shape[1], temp_curr_obs.shape[2])\n",
    "            q, _, _ = train_model.predict([temp_curr_obs, temp_curr_obs,empty_by_one, empty_exp_action_by_one,empty_action_len_by_one])\n",
    "            action_command = np.argmax(q)\n",
    "        \n",
    "        if epsilon > epsilon_min:\n",
    "            epsilon -= (epsilon_start - epsilon_min) / explore_ts\n",
    "        \n",
    "        _obs, _rew, _done, _info = env.step(action_command)\n",
    "        \n",
    "        _rew = np.sign(_rew) * np.log(1.+np.abs(_rew))\n",
    "        \n",
    "        nstep_state_deque.append(curr_obs)\n",
    "        nstep_action_deque.append(action_command)\n",
    "        nstep_rew_list.append(_rew)\n",
    "        nstep_nexts_deque.append(_obs)\n",
    "        nstep_done_deque.append(_done)\n",
    "        \n",
    "        if episode_start_ts > 10:\n",
    "            add_transition(rep_buffer, nstep_state_deque, nstep_action_deque, nstep_rew_list, nstep_nexts_deque,\n",
    "                           nstep_done_deque, _obs, False, nsteps, nstep_gamma)\n",
    "        if _done:\n",
    "            add_transition(rep_buffer, nstep_state_deque, nstep_action_deque, nstep_rew_list, nstep_nexts_deque,\n",
    "                           nstep_done_deque, _obs, False, nsteps, nstep_gamma)\n",
    "            \n",
    "            episode += 1\n",
    "            \n",
    "            curr_obs = env.reset()\n",
    "            \n",
    "            nstep_state_deque.clear()\n",
    "            nstep_action_deque.clear()\n",
    "            nstep_rew_list.clear()\n",
    "            nstep_nexts_deque.clear()\n",
    "            nstep_done_deque.clear()\n",
    "            \n",
    "            episode_start_ts = 0\n",
    "        else:\n",
    "            curr_obs = _obs\n",
    "        \n",
    "        if train_ts > min_buffer_size:\n",
    "            \n",
    "            exp_minibatch = exp_buffer.sample(exp_batch_size)\n",
    "            exp_zip_batch = []\n",
    "            \n",
    "            for i in exp_minibatch:\n",
    "                exp_zip_batch.append(i['sample'])\n",
    "            \n",
    "            exp_states_batch, exp_action_batch, exp_reward_batch, exp_next_states_batc, \\\n",
    "            exp_done_batch, exp_nstep_rew_batch, exp_nstep_next_batch = map(np.array, zip(*exp_zip_batch))\n",
    "            \n",
    "            is_expert_input = np.zeros((batch_size, 1))\n",
    "            is_expert_input[0:exp_batch_size, 0] = 1\n",
    "            # expert action made into a 2d array for when tf.gather_nd is called during training\n",
    "            input_exp_action = np.zeros((batch_size, 2))\n",
    "            input_exp_action[:, 0] = np.arange(batch_size)\n",
    "            input_exp_action[0:exp_batch_size, 1] = exp_action_batch\n",
    "            expert_margin_array = np.ones((batch_size,action_len)) * expert_margin\n",
    "            expert_margin_array[np.arange(exp_batch_size),exp_action_batch] = 0.\n",
    "            \n",
    "            minibatch = rep_buffer.sample(gen_batch_size)\n",
    "            zip_batch = []\n",
    "            \n",
    "            for i in minibatch:\n",
    "                zip_batch.append(i['sample'])\n",
    "            states_batch, action_batch, reward_batch, next_states_batch, done_batch, \\\n",
    "            nstep_rew_batch, nstep_next_batch, = map(np.array, zip(*zip_batch))\n",
    "            \n",
    "            concat_states = np.concatenate((exp_states_batch, states_batch), axis=0)\n",
    "            concat_next_states = np.concatenate((exp_next_states_batch, next_states_batch), axis=0)\n",
    "            concat_nstep_states = np.concatenate((exp_nstep_next_batch, nstep_next_batch), axis=0)\n",
    "            concat_reward = np.concatenate((exp_reward_batch, reward_batch), axis=0)\n",
    "            concat_done = np.concatenate((exp_done_batch, done_batch), axis=0)\n",
    "            concat_action = np.concatenate((exp_action_batch, action_batch), axis=0)\n",
    "            concat_nstep_rew = np.concatenate((exp_nstep_rew_batch, nstep_rew_batch), axis=0)\n",
    "            \n",
    "            \n",
    "            loss += inner_train_function(train_model, target_model, exp_buffer, rep_buffer,\n",
    "                            concat_states, concat_action, concat_reward, concat_next_states,\n",
    "                            concat_done, concat_nstep_rew, concat_nstep_states, is_expert_input,\n",
    "                            input_exp_action, expert_margin_array, action_len,exp_minibatch,minibatch,\n",
    "                             batch_size, gamma, nstep_gamma,exp_batch_size)\n",
    "            \n",
    "            if train_ts % update_every == 0 and train_ts >= min_buffer_size:\n",
    "                print(\"Saving model weights at DQfD timestep {}. Loss is {}\".format(train_ts,loss))\n",
    "                loss = np.zeros((4,))\n",
    "                zString = \"dqfd_training_weights/model_{}_{}.h5\".format(time_int,train_ts)\n",
    "                train_model.save_weights(zString, overwrite=True)\n",
    "                # updating fixed Q network weights\n",
    "                target_model.load_weights(zString)\n",
    "\n",
    "        #info logged and videos recorded through env\n",
    "        print(\"Saving final model weights. Loss is {}\".format(loss))\n",
    "        zString = \"dqfd_training_weights/final_model_{}_{}.h5\".format(time_int, train_ts)\n",
    "        train_model.save_weights(zString, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_train_function(train_model, target_model, exp_buffer, replay_buffer,\n",
    "                         states_batch, action_batch, reward_batch,\n",
    "                         next_states_batch, done_batch, nstep_rew_batch, nstep_next_batch,\n",
    "                         is_expert_input, expert_action_batch, expert_margin,\n",
    "                         action_len, exp_minibatch, minibatch,\n",
    "                         batch_size=32, gamma=0.99, nstep_gamma=0.99, exp_batch_size=8):\n",
    "  \n",
    "  empty_batch_by_one = np.zeros((batch_size, 1))\n",
    "  empty_action_batch = np.zeros((batch_size, 2))\n",
    "  empty_action_batch[:,0] = np.arange(batch_size)\n",
    "  empty_batch_by_action_len = np.zeros((batch_size, action_len))\n",
    "  ti_tuple = tuple([i for i in range(batch_size)])\n",
    "  nstep_final_gamma = nstep_gamma ** 10\n",
    "\n",
    "  q_values_next_target, nstep_q_values_next_target, _ = target_model.predict(\n",
    "      [next_states_batch, nstep_next_batch,\n",
    "       empty_batch_by_one, empty_action_batch,\n",
    "       empty_batch_by_action_len]) #\n",
    "  \n",
    "  q_values_next_train, nstep_q_values_next_train, _ = train_model.predict(\n",
    "      [next_states_batch, nstep_next_batch,\n",
    "       empty_batch_by_one, empty_action_batch,\n",
    "       empty_batch_by_action_len])\n",
    "  \n",
    "  action_max = np.argmax(q_values_next_train, axis=1)\n",
    "  nstep_action_max = np.argmax(nstep_q_values_next_train, axis=1)\n",
    "\n",
    "  dq_targets, nstep_targets, _ = train_model.predict([states_batch, states_batch, is_expert_input,\n",
    "                                                       expert_action_batch, expert_margin])\n",
    "  \n",
    "  dq_targets[ti_tuple, action_batch] = reward_batch + \\\n",
    "                                      (1 - done_batch) * gamma \\\n",
    "                                      * q_values_next_target[np.arange(batch_size), action_max]\n",
    "\n",
    "  nstep_targets[ti_tuple, action_batch] = nstep_rew_batch + \\\n",
    "                                          (1 - done_batch) * nstep_final_gamma \\\n",
    "                                          * nstep_q_values_next_target[np.arange(batch_size), nstep_action_max]\n",
    "\n",
    "  dq_pred, nstep_pred, slmc_pred = train_model.predict_on_batch([states_batch, states_batch,\n",
    "                                                                 is_expert_input, expert_action_batch, expert_margin])\n",
    "  \n",
    "  dq_loss = np.square(dq_pred[np.arange(batch_size),action_batch]-dq_targets[np.arange(batch_size),action_batch])\n",
    "  nstep_loss = np.square(nstep_pred[np.arange(batch_size), action_batch] - nstep_targets[np.arange(batch_size), action_batch])\n",
    "\n",
    "  loss = train_model.train_on_batch([states_batch, states_batch, is_expert_input, expert_action_batch, expert_margin],\n",
    "                                    [dq_targets, nstep_targets, empty_batch_by_one])\n",
    "  \n",
    "  dq_loss_weighted = np.reshape(dq_loss, (batch_size, 1))/np.sum(dq_loss)*loss[1] * batch_size\n",
    "  nstep_loss_weighted = np.reshape(nstep_loss, (batch_size, 1))/np.sum(nstep_loss)*loss[2]*batch_size\n",
    "\n",
    "  sample_losses = dq_loss_weighted + nstep_loss_weighted + np.abs(slmc_pred)\n",
    "\n",
    "  if replay_buffer is not None:\n",
    "    exp_buffer.update_weights(exp_minibatch, sample_losses[:exp_batch_size])\n",
    "    rep_buffer.update_weights(minibatch, sample_losses[-(batch_size-exp_batch_size):])\n",
    "  else:\n",
    "    exp_buffer.update_weights(exp_minibatch, sample_losses)\n",
    "\n",
    "\n",
    "  return np.array(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
